{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38626c46-0abc-4db3-b4c8-3372cafa1611",
   "metadata": {},
   "source": [
    "# Importar las librerias\n",
    "Para este ejercicio debemos usar pandas para el manejo del conjunto de datos y sklearn como libreria de ML para entrenar y evaluar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2097edb-3e93-4c7e-a436-e7d351365cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5647a-3ff2-4249-8bf9-bcb444340e96",
   "metadata": {},
   "source": [
    "# EDA - Machine Predictive Maintenance Classification\n",
    "Usaremos un dataset para matenimiento predictivo que fue ya preparado para un ejercicio de clasificacion, donde se debe usar los datos con dos objetivos:\n",
    "1. determinar su hay falla\n",
    "2. determinar el tipo de falla\n",
    "\n",
    "las columnas son:\n",
    "* Type: calidad del producto, alta (H) media (M) o baja (L))\n",
    "* Air temperature [K]: Temperatura medida del ambiente\n",
    "* Process temperature [K]: temperatura medida del proceso\n",
    "* Rotational speed [rpm]: velocidad calculada a partir de la pontencia\n",
    "* Torque [Nm]: torque\n",
    "* Tool wear [min]: desgaste por minuto\n",
    "* target: hay falla o no\n",
    "* Failure Type: tipo de falla si la hay\n",
    "\n",
    "Se puede visualizar y explorar mas el dataset en https://www.kaggle.com/shivamb/machine-predictive-maintenance-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636e890-f8c8-4f5a-ae3a-4ccc4088dce8",
   "metadata": {},
   "source": [
    "Importamos los datos desde el CSV y vemos las primeras filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f5b6e-5679-467a-8790-f6893b78a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [\"UDI\",\"Product ID\",\"Type\",\"Air temperature [K]\",\"Process temperature [K]\",\"Rotational speed [rpm]\",\"Torque [Nm]\",\"Tool wear [min]\",\"Target\", \"Failure Type\"]\n",
    "df = pd.read_csv(\"predictive_maintenance.csv\", \n",
    "                        sep=\",\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7b55c-8a80-4af2-b306-698a8da89d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tambien podemos ver el tamaño de dafaframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f447c-7890-4678-93bb-0609d7b0b3a0",
   "metadata": {},
   "source": [
    "Como ejercicio para el analisis del dataset podriamos usar pandas para evaluar las siguientes preguntas:\n",
    "* ¿Que relacion tiene el tipo (Type) de producto con la posibilidad de fallar o el tipo de falla?\n",
    "* ¿Cuales son los tipos de falla?\n",
    "* ¿Que variable tiene mas incidencia en cada tipo de falla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9dc1874b-e76b-491c-b35c-2d6ba43059de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     No Failure\n",
      "50                 Power Failure\n",
      "77             Tool Wear Failure\n",
      "160           Overstrain Failure\n",
      "1221             Random Failures\n",
      "3236    Heat Dissipation Failure\n",
      "Name: Failure Type, dtype: object\n",
      "['No Failure', 'Power Failure', 'Tool Wear Failure', 'Overstrain Failure', 'Random Failures', 'Heat Dissipation Failure']\n"
     ]
    }
   ],
   "source": [
    "failures_serie = df.drop_duplicates(subset = [\"Failure Type\"])[\"Failure Type\"]\n",
    "print(failures_serie)  #esto es una serie\n",
    "failures_list = []\n",
    "#vamos a sacar la serie en forma de lista \"just in case\"\n",
    "for i in failures_serie:\n",
    "    failures_list.append(i)\n",
    "print(failures_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420bac-988d-4b2d-9c9c-435e4a627c99",
   "metadata": {},
   "source": [
    "Ahora el primer reto es determinar cual variable incide mas en cada tipo de falla. \n",
    "\n",
    "Desde el campo de la ingenieria mecanica se espera que:\n",
    "* Overstrain Failure (sobreesfuerzo) se deba a un torque excesivo\n",
    "* Tool Wear Failure (desgaste) se deba al desgaste acelerado de la herramienta\n",
    "* Heat Dissipation Failure (perdida de calor) se evidencia en una alta temperatura ambiente o de proceso\n",
    "* Power Failure (potencia) se deba a un aumento en la velocidad de rotacion y el torque P=T*w\n",
    "\n",
    "Para hacer el analisis, pero vamos a crear un df que solo contenga la columnas y filas de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "16dde9a3-9f8e-4165-a1c2-2571a728eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type  Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
      "0     1                298.1                    308.6                    1551   \n",
      "1     0                298.2                    308.7                    1408   \n",
      "2     0                298.1                    308.5                    1498   \n",
      "3     0                298.2                    308.6                    1433   \n",
      "4     0                298.2                    308.7                    1408   \n",
      "\n",
      "   Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
      "0         42.8                0       0   No Failure  \n",
      "1         46.3                3       0   No Failure  \n",
      "2         49.4                5       0   No Failure  \n",
      "3         39.5                7       0   No Failure  \n",
      "4         40.0                9       0   No Failure  \n"
     ]
    }
   ],
   "source": [
    "#dfa = df.drop(['UDI', 'Product ID'], axis=1)[df[\"Failure Type\"] != \"No Failure\"] #en caso de querar dejar solo las fallas\n",
    "dfa = df.drop(['UDI', 'Product ID'], axis=1)\n",
    "type_number = []\n",
    "for i in dfa[\"Type\"]:\n",
    "    if i == \"L\":\n",
    "        type_number.append(0)\n",
    "    elif i == \"M\":\n",
    "        type_number.append(1)\n",
    "    else:\n",
    "        type_number.append(2)\n",
    "dfa[\"Type\"] = type_number #cambiamos las etiquetas por numeros\n",
    "print(dfa.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e4908-4292-4761-857d-2ec1175edce3",
   "metadata": {},
   "source": [
    "### ¿Cual variable indice mas en cada falla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c23c3398-37c7-4b4f-882c-40fe779de301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heat Dissipation Failure</th>\n",
       "      <td>302.567857</td>\n",
       "      <td>310.799107</td>\n",
       "      <td>1337.964286</td>\n",
       "      <td>52.778571</td>\n",
       "      <td>107.339286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Failure</th>\n",
       "      <td>299.972855</td>\n",
       "      <td>309.994343</td>\n",
       "      <td>1540.324389</td>\n",
       "      <td>39.624316</td>\n",
       "      <td>106.678927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overstrain Failure</th>\n",
       "      <td>299.867949</td>\n",
       "      <td>310.051282</td>\n",
       "      <td>1354.243590</td>\n",
       "      <td>56.878205</td>\n",
       "      <td>208.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Power Failure</th>\n",
       "      <td>300.075789</td>\n",
       "      <td>309.954737</td>\n",
       "      <td>1763.968421</td>\n",
       "      <td>48.514737</td>\n",
       "      <td>101.884211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Failures</th>\n",
       "      <td>300.766667</td>\n",
       "      <td>310.755556</td>\n",
       "      <td>1489.444444</td>\n",
       "      <td>43.522222</td>\n",
       "      <td>119.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tool Wear Failure</th>\n",
       "      <td>300.288889</td>\n",
       "      <td>310.164444</td>\n",
       "      <td>1570.666667</td>\n",
       "      <td>37.226667</td>\n",
       "      <td>216.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Air temperature [K]  Process temperature [K]  \\\n",
       "Failure Type                                                             \n",
       "Heat Dissipation Failure           302.567857               310.799107   \n",
       "No Failure                         299.972855               309.994343   \n",
       "Overstrain Failure                 299.867949               310.051282   \n",
       "Power Failure                      300.075789               309.954737   \n",
       "Random Failures                    300.766667               310.755556   \n",
       "Tool Wear Failure                  300.288889               310.164444   \n",
       "\n",
       "                          Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  \n",
       "Failure Type                                                                    \n",
       "Heat Dissipation Failure             1337.964286    52.778571       107.339286  \n",
       "No Failure                           1540.324389    39.624316       106.678927  \n",
       "Overstrain Failure                   1354.243590    56.878205       208.217949  \n",
       "Power Failure                        1763.968421    48.514737       101.884211  \n",
       "Random Failures                      1489.444444    43.522222       119.888889  \n",
       "Tool Wear Failure                    1570.666667    37.226667       216.555556  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quitamos en type y target porque no tiene sentido promediarlos\n",
    "dfa.drop([\"Type\", \"Target\"], axis=1).groupby(by=\"Failure Type\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715cdbe-e640-47d4-bb69-20d589eb3035",
   "metadata": {},
   "source": [
    "### ¿Cual es la relacion entre la calidad del producto y la posibilidad de falla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f4ab58e0-7916-4932-b514-57a17dfe1527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Failure Type              Type\n",
       "Heat Dissipation Failure  0       74\n",
       "                          1       30\n",
       "                          2        8\n",
       "Overstrain Failure        0       73\n",
       "                          1        4\n",
       "                          2        1\n",
       "Power Failure             0       59\n",
       "                          1       31\n",
       "                          2        5\n",
       "Random Failures           0       12\n",
       "                          1        2\n",
       "                          2        4\n",
       "Tool Wear Failure         0       25\n",
       "                          1       14\n",
       "                          2        6\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no nos interesa ver las no fallas porque crearia sesgo\n",
    "dfa[df[\"Failure Type\"] != \"No Failure\"].groupby(by=[\"Failure Type\",\"Type\"])[\"Type\"].count()\n",
    "#tarea: calcular el porcentaje de fallas por calidad y para cada tipo de falla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a643746f-0544-4e5e-8790-925f0d348b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Failure\n",
      "0:  0.621\n",
      "1:  0.326\n",
      "2:  0.053\n",
      "Tool Wear Failure\n",
      "0:  0.556\n",
      "1:  0.311\n",
      "2:  0.133\n",
      "Overstrain Failure\n",
      "0:  0.936\n",
      "1:  0.051\n",
      "2:  0.013\n",
      "Random Failures\n",
      "0:  0.667\n",
      "1:  0.111\n",
      "2:  0.222\n",
      "Heat Dissipation Failure\n",
      "0:  0.661\n",
      "1:  0.268\n",
      "2:  0.071\n"
     ]
    }
   ],
   "source": [
    "sfa = dfa[df[\"Failure Type\"] != \"No Failure\"].groupby(by=[\"Failure Type\",\"Type\"])[\"Type\"].count()\n",
    "failures_list2 = failures_list\n",
    "failures_list2.remove(\"No Failure\")\n",
    "for i in failures_list2:\n",
    "    print(i)\n",
    "    for j in range(3):\n",
    "        print(str(j) + \":  \" + str(round(sfa[i][j]/(sfa[i][0]+sfa[i][1]+sfa[i][2]),3)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426195d-916a-498f-b14e-1f8dff5fc219",
   "metadata": {},
   "source": [
    "Este utimo analisis nos lleva a una conclusion muy importante y es que las piezas de menor calidad siempre van a fallar de forma mucho mas frecuente, en especial por sobre carga.\n",
    "\n",
    "Mas a fondo se debe hacer el analisis sobre el costo/beneficio de tener una pieza de mejor calidad. \n",
    "\n",
    "Se debe evitar aplicar mucho torque cuando se usen piezas de menos calidad. ¿por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd3b5e-dee0-46ae-a346-4aad24128219",
   "metadata": {},
   "source": [
    "### ¿Cuales son las fallas mas frecuentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ca68945b-00c8-4022-8803-1956c87a5976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Failure Type\n",
       "Heat Dissipation Failure    22.4\n",
       "Overstrain Failure          15.6\n",
       "Power Failure               19.0\n",
       "Random Failures              3.6\n",
       "Tool Wear Failure            9.0\n",
       "Name: Failure Type, dtype: float64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfa2 = dfa[df[\"Failure Type\"] != \"No Failure\"].groupby(by=[\"Failure Type\"])[\"Failure Type\"]\n",
    "sfa2.count()/sfa2.count().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6aaff3-4386-4725-8693-376bd712c2f0",
   "metadata": {},
   "source": [
    "# Preparacion de los datos para el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b13abe96-18bf-4625-b2a4-93da7e71b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"Air temperature [K]\",\"Process temperature [K]\",\"Rotational speed [rpm]\",\"Torque [Nm]\",\"Tool wear [min]\"]\n",
    "target_col = [\"Target\"]\n",
    "X = dfa[feature_cols]\n",
    "y = dfa[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8f955-becf-4507-887d-602b5b1b9077",
   "metadata": {},
   "source": [
    "# Entrenar y evaluar el modelo\n",
    "Para entrenar el modelo, primer creamos un objeto <DecisionTreeClassifier> sobre la cual se puede especificar varios parametros como se detalla en el API https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "    \n",
    "Despues usamos el metodo <fit> para realizar el entrenamiento entregando como argumentos los features (X) y los targets (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "883634bd-a98a-4383-a763-32a91686d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier() #crear el classifier con todo por defecto\n",
    "clf = clf.fit(X_train,y_train) #entrenar el modelo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c699b-a962-42bc-8855-9ef05d684b58",
   "metadata": {},
   "source": [
    "Para usar el modelo con datos nuevos, se debe usar el metodo predict, que resive una lista o arreglo de datos a evaluar y retorna un arreglo de respuestas. El modelo siempre se debe evaluar sobre datos que no esten en el conjunto de entrenamiento, por eso previamente separamos un subconjunto llamado X_test y y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8e17e14a-54ff-42be-9833-6c5464aac825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13e237-1228-4b61-8a94-5d0ab98e19ad",
   "metadata": {},
   "source": [
    "### Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8b0d6ba2-ef54-4909-a8a8-cf6e48a1094f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7000, 3000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PCJUAN~1\\AppData\\Local\\Temp/ipykernel_17780/2120807250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7000, 3000]"
     ]
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba191de-e02d-45dc-abd9-9f9cd6a7c03a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Esto parece una prediccion muy buena, pero es peligrosa porque la mayoria de nuestros datos son de un mismo target, es decir, los datos de entrenamiento estan desvalanceados y esto puede hacer que el modelo se ajuste por la cantidad y no por las metricas deseadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576019d-551b-44cb-8ed7-69fb975b1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train[\"Target\"]==0].count()/y_train.count() #porcentaje de datos que son 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d06c7d-c7e7-43eb-8b23-677fc6904e7f",
   "metadata": {},
   "source": [
    "Para mejorar esta situacion, podemos equilibrar los datos dejando un 40% para fallas y un 60% para no fallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7bcaa-e087-4589-8d0d-2f8c36c4190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacamos un df solo con las fallas\n",
    "dfa_1 = dfa[df[\"Target\"] != 0]\n",
    "#sacamos un df solo con las no fallas pero 1.2 veces mas grande que el dfa_1\n",
    "dfa_2 = dfa[df[\"Target\"] == 0].sample(int(len(dfa_1)*1.2))\n",
    "#concatenamos para crear el definitivo\n",
    "dfa_3 = pd.concat([dfa_1, dfa_2])\n",
    "X = dfa_3[feature_cols]\n",
    "y = dfa_3[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb346ab-9747-45b3-888e-d016acf9fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier() #crear el classifier con todo por defecto\n",
    "clf = clf.fit(X_train,y_train) #entrenar el modelo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879338e2-b051-43e4-8eb4-53bc8a11eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6c399-10db-4a94-9c62-e67e5f90c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76afdff-dda8-4cdb-ac6f-c8e4286593d5",
   "metadata": {},
   "source": [
    "vemos que la precision se redujo, pero es normal la reducir tanto el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb039ab-400a-4921-88ea-6731382b3f6c",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Ahora aplicaremos lo mismo para el random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98e270-9dce-4946-af62-33730c1d6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d96be8-029a-4b09-aff7-8a8b35605540",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2.fit(X_train, y_train.values.ravel()) #notar que se debe usar .values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db7865-aaf5-417d-ab1d-2ef74687051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3411a-a6eb-4edf-9484-de565f66f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7363bc-d133-40e4-be22-0d65066567fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "for i in range(20):\n",
    "    j = j+0.1\n",
    "    dfa_1 = dfa[df[\"Target\"] != 0]\n",
    "    dfa_2 = dfa[df[\"Target\"] == 0].sample(int(len(dfa_1)*j))\n",
    "    dfa_3 = pd.concat([dfa_1, dfa_2])\n",
    "    clf_1 = DecisionTreeClassifier(max_depth=3, random_state=0) #crear el classifier con todo por defecto\n",
    "    clf_2 = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "    print(\"j: \" + str(j))\n",
    "    #print(\"DT: \" + str(cross_val_score(clf_1, X, y, cv = 5).mean()))\n",
    "    #print(\"RF: \" + str(cross_val_score(clf_2, X, y.values.ravel(), cv = 5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715885c-fc16-4225-8dba-a2df0875ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
